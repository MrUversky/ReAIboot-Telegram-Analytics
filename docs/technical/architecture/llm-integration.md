# Интеграция с LLM

## Обзор

Этот документ описывает интеграцию системы с моделями искусственного интеллекта.

## Используемые модели

- **Claude 3.5 Sonnet** - основной движок для генерации контента
- **GPT-4o** - резервная модель для сложных задач

## Архитектура взаимодействия

### Основной поток:
1. Получение запроса от API
2. Подготовка промпта через PromptManager
3. Отправка запроса к LLM
4. Обработка и парсинг ответа
5. Сохранение результатов

## Компоненты интеграции

### LLMOrchestrator
Основной координатор всех LLM операций.

### Специализированные процессоры:
- FilterProcessor - фильтрация контента
- AnalysisProcessor - анализ постов
- RubricSelectorProcessor - выбор рубрики и формата
- GeneratorProcessor - генерация сценариев

## Промпты и шаблоны

Все промпты хранятся в базе данных Supabase в таблице `prompt_templates`.

## Обработка ошибок

- Таймауты запросов
- Парсинг невалидного JSON
- Fallback на резервные модели

## Интеграция с LLM

### Интеграция: llm/process

**Файл:** `src/api_main.py`

**Контекст:**         logger.error(f"Ошибка в enhanced фоновой обработке: {e}")

**Тип взаимодействия:** [API вызов / Обработка ответа / Управление промптами]

**Модель:** [Claude / GPT / другая]

**Назначение:** [Требуется описание]


### Интеграция: prompt_manager.

**Файл:** `src/app/llm/orchestrator.py`

**Контекст:**                             # Также обновляем duration для использования в промпте

**Тип взаимодействия:** [API вызов / Обработка ответа / Управление промптами]

**Модель:** [Claude / GPT / другая]

**Назначение:** [Требуется описание]
