#!/usr/bin/env python3
"""
Documentation Auto-Update Script

Automatically updates documentation based on code changes.
This script analyzes code changes and generates/updates corresponding documentation.
"""

import argparse
import json
import logging
import os
import re
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    pass  # dotenv optional

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

logger = logging.getLogger(__name__)


@dataclass
class CodeChange:
    """Represents a code change"""

    file_path: str
    change_type: str  # 'added', 'modified', 'deleted'
    content: str
    line_number: Optional[int] = None


@dataclass
class DocumentationUpdate:
    """Represents a documentation update"""

    file_path: str
    content: str
    change_type: str  # 'create', 'update', 'delete'


class DocumentationAgent:
    """Main class for documentation updates"""

    def __init__(self, project_root: str, force_ai: bool = False):
        self.project_root = Path(project_root)
        self.docs_root = self.project_root / "docs"
        self.api_docs_root = self.docs_root / "technical" / "api" / "endpoints"
        self.force_ai = force_ai

        # Performance metrics
        self.metrics = {
            "start_time": None,
            "end_time": None,
            "files_analyzed": 0,
            "changes_found": 0,
            "updates_applied": 0,
            "errors": [],
        }

    def analyze_changes(self, changed_files: List[str]) -> List[CodeChange]:
        """Analyze changed files and extract relevant changes"""
        changes = []
        self.metrics["start_time"] = time.time()
        self.metrics["files_analyzed"] = len(changed_files)

        for i, file_path in enumerate(changed_files):
            full_path = self.project_root / file_path

            if not full_path.exists():
                continue

            # Analyze file based on type
            if file_path.endswith(".py"):
                file_changes = self._analyze_python_file(file_path, full_path)
                changes.extend(file_changes)
            elif file_path.endswith((".js", ".ts", ".tsx")):
                file_changes = self._analyze_javascript_file(file_path, full_path)
                changes.extend(file_changes)
            elif file_path.endswith(".sql"):
                file_changes = self._analyze_sql_file(file_path, full_path)
                changes.extend(file_changes)
            elif file_path.endswith(".yaml") or file_path.endswith(".yml"):
                file_changes = self._analyze_config_file(file_path, full_path)
                changes.extend(file_changes)

            # Analyze Python files for business logic (additional to API analysis)
            if file_path.endswith(".py") and not "test" in file_path.lower():
                business_changes = self._analyze_business_logic_file(
                    file_path, full_path
                )
                changes.extend(business_changes)

        # Update metrics
        self.metrics["changes_found"] = len(changes)
        self.metrics["end_time"] = time.time()

        return changes

    def _analyze_python_file(self, file_path: str, full_path: Path) -> List[CodeChange]:
        """Analyze Python file for API endpoints and functions"""
        changes = []

        with open(full_path, "r", encoding="utf-8") as f:
            content = f.read()

        # Find FastAPI endpoints
        endpoint_pattern = r'@app\.(get|post|put|delete|patch)\s*\(\s*r?[\'"]([^\'"]+)[\'"]\s*.*?\)\s*async def\s+(\w+)'
        matches = re.finditer(endpoint_pattern, content, re.MULTILINE | re.DOTALL)

        for match in matches:
            method, path, func_name = match.groups()
            line_number = content[: match.start()].count("\n") + 1

            # Extract function signature and docstring
            func_start = match.end()
            func_end_pattern = r"(?=@app\.|\nclass|\ndef|\n@|$)"
            func_end_match = re.search(
                func_end_pattern, content[func_start:], re.MULTILINE
            )

            if func_end_match:
                func_content = content[func_start : func_start + func_end_match.start()]
            else:
                func_content = content[func_start:]

            changes.append(
                CodeChange(
                    file_path=file_path,
                    change_type="api_endpoint",
                    content=f"Method: {method.upper()}\nPath: {path}\nFunction: {func_name}\nContent: {func_content[:500]}...",
                    line_number=line_number,
                )
            )

        return changes

    def _analyze_sql_file(self, file_path: str, full_path: Path) -> List[CodeChange]:
        """Analyze SQL file for schema changes"""
        changes = []

        with open(full_path, "r", encoding="utf-8") as f:
            content = f.read()

        # Find table creation/alteration
        table_pattern = r"(CREATE TABLE|ALTER TABLE|DROP TABLE)\s+(\w+)"
        matches = re.finditer(table_pattern, content, re.IGNORECASE)

        for match in matches:
            operation, table_name = match.groups()
            line_number = content[: match.start()].count("\n") + 1

            changes.append(
                CodeChange(
                    file_path=file_path,
                    change_type="database_schema",
                    content=f"Operation: {operation}\nTable: {table_name}",
                    line_number=line_number,
                )
            )

        return changes

    def _analyze_config_file(self, file_path: str, full_path: Path) -> List[CodeChange]:
        """Analyze configuration files for changes"""
        changes = []

        with open(full_path, "r", encoding="utf-8") as f:
            content = f.read()

        # For now, just mark config files as changed
        # In future, could parse specific config formats
        changes.append(
            CodeChange(
                file_path=file_path,
                change_type="configuration",
                content=f"Configuration file: {file_path}",
                line_number=1,
            )
        )

        return changes

    def _analyze_javascript_file(
        self, file_path: str, full_path: Path
    ) -> List[CodeChange]:
        """Analyze JavaScript/TypeScript file for components and functions"""
        changes = []

        with open(full_path, "r", encoding="utf-8") as f:
            content = f.read()

        lines = content.split("\n")

        # Find React components (function/class components)
        component_patterns = [
            r"^function\s+(\w+)\s*\(",  # Function components
            r"^const\s+(\w+)\s*=\s*\(",  # Arrow function components
            r"^export\s+(?:default\s+)?function\s+(\w+)",  # Exported functions
            r"^export\s+(?:const|function)\s+(\w+)",  # Export declarations
        ]

        for i, line in enumerate(lines):
            for pattern in component_patterns:
                match = re.match(pattern, line.strip())
                if match:
                    component_name = match.group(1)
                    if not component_name.startswith("_"):  # Skip private components
                        component_info = self._extract_js_component_info(content, i)
                        changes.append(
                            CodeChange(
                                file_path=file_path,
                                change_type="frontend_component",
                                content=f"Component: {component_name}\nInfo: {component_info}",
                                line_number=i + 1,
                            )
                        )
                        break  # Only add once per component

        # Find API calls and external integrations
        api_patterns = [
            r"fetch\s*\(",
            r"axios\.",
            r"api\.",
            r"\.post\s*\(",
            r"\.get\s*\(",
        ]

        for pattern in api_patterns:
            for match in re.finditer(pattern, content):
                line_number = content[: match.start()].count("\n") + 1
                context = self._get_context_lines(lines, line_number - 1, 2)
                changes.append(
                    CodeChange(
                        file_path=file_path,
                        change_type="frontend_component",
                        content=f"API call: {match.group()}\nContext: {context}",
                        line_number=line_number,
                    )
                )

        return changes

    def _extract_js_component_info(
        self, content: str, component_line_index: int
    ) -> str:
        """Extract basic information about a JS/TS component"""
        lines = content.split("\n")
        info = []

        # Look for props interface or type
        for i in range(
            component_line_index - 5, min(component_line_index + 10, len(lines))
        ):
            if i >= 0:
                line = lines[i].strip()
                if "interface" in line and "Props" in line:
                    info.append("Has Props interface")
                    break
                elif "type" in line and "=" in line:
                    info.append("Has type definition")
                    break

        # Check for hooks usage
        component_end = min(component_line_index + 50, len(lines))
        component_content = "\n".join(lines[component_line_index:component_end])

        hooks = []
        if "useState" in component_content:
            hooks.append("useState")
        if "useEffect" in component_content:
            hooks.append("useEffect")
        if "useContext" in component_content:
            hooks.append("useContext")

        if hooks:
            info.append(f"Uses hooks: {', '.join(hooks)}")

        return "; ".join(info) if info else "Frontend component"

    def _analyze_business_logic_file(
        self, file_path: str, full_path: Path
    ) -> List[CodeChange]:
        """Analyze Python file for business logic changes (classes, methods, LLM interactions)"""
        changes = []

        with open(full_path, "r", encoding="utf-8") as f:
            content = f.read()

        lines = content.split("\n")

        # Find classes
        class_pattern = r"^class\s+(\w+)"
        for i, line in enumerate(lines):
            class_match = re.match(class_pattern, line)
            if class_match:
                class_name = class_match.group(1)
                # Extract class docstring and basic info
                class_info = self._extract_class_info(content, i)
                changes.append(
                    CodeChange(
                        file_path=file_path,
                        change_type="business_logic",
                        content=f"Class: {class_name}\nInfo: {class_info}",
                        line_number=i + 1,
                    )
                )

        # Find important functions (not API endpoints)
        func_pattern = r"^def\s+(\w+)\s*\("
        for i, line in enumerate(lines):
            func_match = re.match(func_pattern, line)
            if func_match:
                func_name = func_match.group(1)
                # Skip if it's an API endpoint (already analyzed)
                if not any(
                    keyword in func_name.lower()
                    for keyword in ["get", "post", "put", "delete", "patch"]
                ):
                    func_info = self._extract_function_info(content, i)
                    changes.append(
                        CodeChange(
                            file_path=file_path,
                            change_type="business_logic",
                            content=f"Function: {func_name}\nInfo: {func_info}",
                            line_number=i + 1,
                        )
                    )

        # Find LLM-related patterns
        llm_patterns = [
            r"openai\.|claude\.|anthropic\.|gpt-",
            r"client\.chat\.completions\.create",
            r"prompt_manager\.|PromptManager",
            r"LLM.*process|process.*LLM",
        ]

        for pattern in llm_patterns:
            for match in re.finditer(pattern, content, re.IGNORECASE):
                line_number = content[: match.start()].count("\n") + 1
                context = self._get_context_lines(lines, line_number - 1, 3)
                changes.append(
                    CodeChange(
                        file_path=file_path,
                        change_type="business_logic",
                        content=f"LLM interaction: {match.group()}\nContext: {context}",
                        line_number=line_number,
                    )
                )

        return changes

    def _extract_class_info(self, content: str, class_line_index: int) -> str:
        """Extract basic information about a class"""
        lines = content.split("\n")
        info = []

        # Look for docstring
        for i in range(class_line_index + 1, min(class_line_index + 10, len(lines))):
            line = lines[i].strip()
            if '"""' in line or "'''" in line:
                # Found docstring start
                docstring_lines = []
                in_docstring = True
                j = i
                while j < len(lines) and in_docstring:
                    docstring_lines.append(lines[j])
                    if ('"""' in lines[j] or "'''" in lines[j]) and j > i:
                        in_docstring = False
                    j += 1
                if docstring_lines:
                    info.append("Docstring: " + " ".join(docstring_lines)[:200] + "...")
                break

        # Look for __init__ method
        for i in range(class_line_index + 1, min(class_line_index + 20, len(lines))):
            if "def __init__" in lines[i]:
                info.append("Has __init__ method")
                break

        return "; ".join(info) if info else "No additional info"

    def _extract_function_info(self, content: str, func_line_index: int) -> str:
        """Extract basic information about a function"""
        lines = content.split("\n")
        info = []

        # Look for docstring
        for i in range(func_line_index + 1, min(func_line_index + 10, len(lines))):
            line = lines[i].strip()
            if '"""' in line or "'''" in line:
                docstring_lines = []
                in_docstring = True
                j = i
                while j < len(lines) and in_docstring:
                    docstring_lines.append(lines[j])
                    if ('"""' in lines[j] or "'''" in lines[j]) and j > i:
                        in_docstring = False
                    j += 1
                if docstring_lines:
                    info.append("Docstring: " + " ".join(docstring_lines)[:200] + "...")
                break

        # Check function parameters
        func_line = lines[func_line_index]
        if "(" in func_line and ")" in func_line:
            params_start = func_line.find("(")
            params_end = func_line.find(")")
            params = func_line[params_start : params_end + 1]
            if len(params) > 2:  # More than just ()
                info.append(f"Parameters: {params}")

        return "; ".join(info) if info else "No additional info"

    def _get_context_lines(
        self, lines: List[str], start_index: int, num_lines: int
    ) -> str:
        """Get context lines around a specific line"""
        start = max(0, start_index - num_lines)
        end = min(len(lines), start_index + num_lines + 1)
        return "\n".join(lines[start:end])

    def _create_api_section_template(self, section: str) -> str:
        """Create template for API section documentation"""

        section_descriptions = {
            "llm": {
                "title": "LLM API - –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
                "description": "–≠–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å—Ç–æ–≤.",
                "purpose": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ LLM, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.",
            },
            "posts": {
                "title": "Posts API - –ü–æ—Å—Ç—ã –∏ –∫–æ–Ω—Ç–µ–Ω—Ç",
                "description": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–∞–º–∏ Telegram, —Ä–∞—Å—á–µ—Ç –≤–∏—Ä—É—Å–Ω–æ—Å—Ç–∏, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞.",
                "purpose": "CRUD –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –ø–æ—Å—Ç–∞–º–∏, —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏, –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.",
            },
            "sandbox": {
                "title": "Sandbox API - –ü–µ—Å–æ—á–Ω–∏—Ü–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
                "description": "–û—Ç–ª–∞–¥–æ—á–Ω–∞—è —Å—Ä–µ–¥–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è LLM –ø–∞–π–ø–ª–∞–π–Ω–∞ –∏ –æ—Ç–ª–∞–¥–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.",
                "purpose": "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–æ–≤, –æ—Ç–ª–∞–¥–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥.",
            },
            "admin": {
                "title": "Admin API - –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ",
                "description": "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞–º–∏, —Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.",
                "purpose": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–æ–π, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è.",
            },
            "general": {
                "title": "General API - –û–±—â–∏–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã",
                "description": "–û–±—â–∏–µ API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π.",
                "purpose": "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã, –ø–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏.",
            },
        }

        desc = section_descriptions.get(
            section,
            {
                "title": f"API {section.title()}",
                "description": f"–≠–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å {section}.",
                "purpose": f"–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é {section}.",
            },
        )

        return f"""# {desc['title']}

## –û–±–∑–æ—Ä

{desc['description']}

### –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ
{desc['purpose']}

### –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
–í—Å–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã —Ç—Ä–µ–±—É—é—Ç –≤–∞–ª–∏–¥–Ω–æ–π –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ API –∫–ª—é—á–∏ –∏–ª–∏ Bearer —Ç–æ–∫–µ–Ω—ã.

### –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö
- **Request/Response**: JSON
- **Encoding**: UTF-8
- **Errors**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—à–∏–±–æ–∫ API

---

## –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã
"""

    def generate_documentation_updates(
        self, changes: List[CodeChange]
    ) -> List[DocumentationUpdate]:
        """Generate documentation updates based on code changes"""
        updates = []

        for change in changes:
            if change.change_type == "api_endpoint":
                update = self._generate_api_docs(change)
                if update:
                    updates.append(update)
            elif change.change_type == "database_schema":
                update = self._generate_db_docs(change)
                if update:
                    updates.append(update)
            elif change.change_type == "business_logic":
                update = self._generate_architecture_docs(change)
                if update:
                    updates.append(update)
            elif change.change_type == "frontend_component":
                update = self._generate_frontend_docs(change)
                if update:
                    updates.append(update)
            elif change.change_type == "configuration":
                # TODO: –î–æ–±–∞–≤–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
                logger.info(f"Configuration change detected: {change.file_path}")

        return updates

    def _generate_api_docs(self, change: CodeChange) -> Optional[DocumentationUpdate]:
        """Generate API documentation for endpoint"""
        lines = change.content.split("\n")
        method = None
        path = None
        func_name = None

        for line in lines:
            if line.startswith("Method: "):
                method = line.replace("Method: ", "")
            elif line.startswith("Path: "):
                path = line.replace("Path: ", "")
            elif line.startswith("Function: "):
                func_name = line.replace("Function: ", "")

        if not all([method, path, func_name]):
            return None

        # Determine which API section this belongs to
        if "/posts" in path:
            section = "posts"
        elif "/llm" in path:
            section = "llm"
        elif "/sandbox" in path:
            section = "sandbox"
        elif "/admin" in path or "admin" in path:
            section = "admin"
        else:
            section = "general"

        docs_path = self.api_docs_root / f"{section}.md"

        # Check if docs file exists
        if docs_path.exists():
            # Update existing file
            with open(docs_path, "r", encoding="utf-8") as f:
                current_content = f.read()

            # Check if endpoint already documented
            if f"**–≠–Ω–¥–ø–æ–∏–Ω—Ç:** `{method} {path}`" in current_content:
                logger.info(f"Endpoint {method} {path} already documented")
                return None

            # Add new endpoint documentation
            new_content = self._generate_endpoint_section(
                method, path, func_name, change.content
            )
            updated_content = current_content + "\n\n" + new_content

            return DocumentationUpdate(
                file_path=str(docs_path), content=updated_content, change_type="update"
            )
        else:
            # Create new file with proper template
            template = self._create_api_section_template(section)
            content = (
                template
                + "\n\n"
                + self._generate_endpoint_section(
                    method, path, func_name, change.content
                )
            )

            return DocumentationUpdate(
                file_path=str(docs_path), content=content, change_type="create"
            )

    def _generate_endpoint_section(
        self, method: str, path: str, func_name: str, details: str
    ) -> str:
        """Generate documentation section for an endpoint"""
        section = f"""## {func_name.replace('_', ' ').title()}

**–≠–Ω–¥–ø–æ–∏–Ω—Ç:** `{method} {path}`

**–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è:** API Key

### –û–ø–∏—Å–∞–Ω–∏–µ
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ {func_name}.

### –î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
```
Function: {func_name}
Location: {details.split('Location: ')[1] if 'Location: ' in details else 'Unknown'}
```

---

*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        return section

    def _generate_db_docs(self, change: CodeChange) -> Optional[DocumentationUpdate]:
        """Generate database documentation"""
        # This would be more complex in a real implementation
        logger.info(f"Database change detected: {change.content}")
        return None

    def _generate_architecture_docs(
        self, change: CodeChange
    ) -> Optional[DocumentationUpdate]:
        """Generate architecture documentation for business logic"""
        lines = change.content.split("\n")
        component_type = None
        component_name = None
        component_info = None

        for line in lines:
            if line.startswith("Class: "):
                component_type = "class"
                component_name = line.replace("Class: ", "")
            elif line.startswith("Function: "):
                component_type = "function"
                component_name = line.replace("Function: ", "")
            elif line.startswith("LLM interaction: "):
                component_type = "llm_interaction"
                component_name = line.replace("LLM interaction: ", "")
            elif line.startswith("Info: ") or line.startswith("Context: "):
                component_info = line.replace("Info: ", "").replace("Context: ", "")

        if not component_type or not component_name:
            return None

        # Determine which architecture document to update
        if component_type == "class":
            docs_path = self.docs_root / "technical" / "architecture" / "components.md"
            section = "–ö–ª–∞—Å—Å—ã –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"
        elif component_type == "function":
            docs_path = self.docs_root / "technical" / "architecture" / "components.md"
            section = "–§—É–Ω–∫—Ü–∏–∏"
        elif component_type == "llm_interaction":
            docs_path = (
                self.docs_root / "technical" / "architecture" / "llm-integration.md"
            )
            section = "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LLM"
        else:
            return None

        # Create architecture docs directory if needed
        docs_path.parent.mkdir(parents=True, exist_ok=True)

        # Check if docs file exists
        if docs_path.exists():
            with open(docs_path, "r", encoding="utf-8") as f:
                current_content = f.read()

            # Check if component already documented
            if f"### {component_name}" in current_content and not self.force_ai:
                logger.info(f"Component {component_name} already documented")
                return None

            change_type = "update"
        else:
            # Create new architecture file
            current_content = self._create_architecture_template(component_type)
            change_type = "create"

        # Generate component documentation
        component_docs = self._generate_component_docs(
            component_type, component_name, component_info, change.file_path
        )

        # Add to appropriate section
        if f"## {section}" in current_content:
            # Insert after section header
            section_pattern = f"## {section}\n"
            insert_position = current_content.find(section_pattern) + len(
                section_pattern
            )
            updated_content = (
                current_content[:insert_position]
                + "\n"
                + component_docs
                + "\n"
                + current_content[insert_position:]
            )
        else:
            # Add new section
            updated_content = current_content + f"\n## {section}\n\n{component_docs}\n"

        return DocumentationUpdate(
            file_path=str(docs_path), change_type=change_type, content=updated_content
        )

    def _create_architecture_template(self, component_type: str) -> str:
        """Create template for architecture documentation"""

        if component_type in ["class", "function"]:
            return """# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

## –û–±–∑–æ—Ä

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–∏—Å—Ç–µ–º—ã ReAIboot.

## –ö–ª–∞—Å—Å—ã –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

–ó–¥–µ—Å—å –æ–ø–∏—Å–∞–Ω—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã —Å–∏—Å—Ç–µ–º—ã –∏ –∏—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ.

## –§—É–Ω–∫—Ü–∏–∏

–ó–¥–µ—Å—å –æ–ø–∏—Å–∞–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∏—Ö —Ä–æ–ª—å –≤ —Å–∏—Å—Ç–µ–º–µ.

## –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

–î–∏–∞–≥—Ä–∞–º–º–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:

```
Frontend (Next.js) <-> API (FastAPI) <-> LLM Services <-> Database (Supabase)
```

## –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ UI
2. API –ø–æ–ª—É—á–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ
3. –î–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –≤ LLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
4. –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
5. –û—Ç–≤–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
"""
        elif component_type == "llm_interaction":
            return """# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LLM

## –û–±–∑–æ—Ä

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å–∏—Å—Ç–µ–º—ã —Å –º–æ–¥–µ–ª—è–º–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.

## –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏

- **Claude 3.5 Sonnet** - –æ—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
- **GPT-4o** - —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è

### –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫:
1. –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –æ—Ç API
2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ —á–µ—Ä–µ–∑ PromptManager
3. –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM
4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

## –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### LLMOrchestrator
–û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –≤—Å–µ—Ö LLM –æ–ø–µ—Ä–∞—Ü–∏–π.

### –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã:
- FilterProcessor - —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
- AnalysisProcessor - –∞–Ω–∞–ª–∏–∑ –ø–æ—Å—Ç–æ–≤
- RubricSelectorProcessor - –≤—ã–±–æ—Ä —Ä—É–±—Ä–∏–∫–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∞
- GeneratorProcessor - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

## –ü—Ä–æ–º–ø—Ç—ã –∏ —à–∞–±–ª–æ–Ω—ã

–í—Å–µ –ø—Ä–æ–º–ø—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö Supabase –≤ —Ç–∞–±–ª–∏—Ü–µ `prompt_templates`.

## –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

- –¢–∞–π–º–∞—É—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤
- –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON
- Fallback –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
"""

        return "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã\n\n–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"

    def _generate_component_docs(
        self,
        component_type: str,
        component_name: str,
        component_info: str,
        file_path: str,
    ) -> str:
        """Generate documentation for a specific component"""

        if component_type == "class":
            return f"""### {component_name}

**–§–∞–π–ª:** `{file_path}`

**–û–ø–∏—Å–∞–Ω–∏–µ:** {component_info}

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏–µ]

**–ú–µ—Ç–æ–¥—ã:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏–µ]

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑]
"""

        elif component_type == "function":
            return f"""### {component_name}

**–§–∞–π–ª:** `{file_path}`

**–°–∏–≥–Ω–∞—Ç—É—Ä–∞:** {component_info}

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏–µ]

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- [–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]

**–í–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑]
"""

        elif component_type == "llm_interaction":
            return f"""### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è: {component_name}

**–§–∞–π–ª:** `{file_path}`

**–ö–æ–Ω—Ç–µ–∫—Å—Ç:** {component_info}

**–¢–∏–ø –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è:** [API –≤—ã–∑–æ–≤ / –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ / –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞–º–∏]

**–ú–æ–¥–µ–ª—å:** [Claude / GPT / –¥—Ä—É–≥–∞—è]

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏–µ]
"""

        # Try to generate AI description if OpenAI is available
        ai_description = self._generate_ai_component_description(
            component_type, component_name, component_info, file_path
        )
        if ai_description:
            return ai_description

        return f"### {component_name}\n\n–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"

    def _generate_ai_component_description(
        self,
        component_type: str,
        component_name: str,
        component_info: str,
        file_path: str,
    ) -> Optional[str]:
        """Generate AI-powered description for component"""
        try:
            import os

            import openai

            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                return None

            client = openai.Client(api_key=api_key)

            # Extract relevant context for AI analysis
            try:
                file_content = self._extract_component_context(file_path, component_name, component_type)
            except Exception as e:
                logger.warning(f"Failed to extract context for {component_name}: {e}")
                file_content = f"File: {file_path}\nComponent: {component_name}\nType: {component_type}\nContext extraction failed."

            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Å–∏—Å—Ç–µ–º—ã ReAIboot –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

            –¢–∏–ø –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞: {component_type}
            –ù–∞–∑–≤–∞–Ω–∏–µ: {component_name}
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {component_info}
            –§–∞–π–ª: {file_path}

            –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–∞ (–ø–µ—Ä–≤—ã–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤):
            {file_content}

            –°–æ–∑–¥–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∫–ª—é—á–∞—é—â–µ–µ:
            1. –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
            2. –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã/—Ñ—É–Ω–∫—Ü–∏–∏
            3. –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ —Å–≤—è–∑–∏ —Å –¥—Ä—É–≥–∏–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
            4. –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

            –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ - Markdown —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.
            """

            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=400,  # Reduced from 500
                temperature=0.3,
            )

            description = response.choices[0].message.content.strip()

            return f"""### {component_name}

**–§–∞–π–ª:** `{file_path}`

**–û–ø–∏—Å–∞–Ω–∏–µ:** {component_info}

{description}
"""

        except Exception as e:
            logger.warning(f"Failed to generate AI description: {e}")
            return None

    def _extract_component_context(self, file_path: str, component_name: str, component_type: str) -> str:
        """Extract relevant context for AI analysis without sending entire file"""
        try:
            with open(self.project_root / file_path, "r", encoding="utf-8") as f:
                content = f.read()
        except:
            return f"Could not read file: {file_path}"

        lines = content.split('\n')
        context_parts = []

        # Add file header info
        context_parts.append(f"File: {file_path}")
        context_parts.append(f"Component: {component_name} ({component_type})")

        # Extract imports (first 10 lines typically)
        imports = []
        for line in lines[:20]:  # Check first 20 lines for imports
            line = line.strip()
            if line.startswith(('import ', 'from ')) and not line.startswith('from typing'):
                imports.append(line)
            if len(imports) >= 5:  # Limit imports
                break
        if imports:
            context_parts.append("\nKey imports:")
            context_parts.extend(imports[:5])

        # Find component definition and extract docstring + method signatures
        in_component = False
        component_start = -1
        brace_count = 0

        for i, line in enumerate(lines):
            stripped = line.strip()

            # Find component start
            if not in_component:
                if component_type == "class" and stripped.startswith(f"class {component_name}"):
                    in_component = True
                    component_start = i
                    # Extract class docstring
                    docstring = self._extract_docstring(lines, i)
                    if docstring:
                        context_parts.append(f"\nClass docstring:\n{docstring}")
                elif component_type == "function" and (stripped.startswith(f"def {component_name}") or stripped.startswith(f"async def {component_name}")):
                    in_component = True
                    component_start = i
                    # Extract function docstring
                    docstring = self._extract_docstring(lines, i)
                    if docstring:
                        context_parts.append(f"\nFunction docstring:\n{docstring}")
                    # For functions, also add the signature
                    context_parts.append(f"\nFunction signature:\n{line}")
                    break  # Functions are simpler, just signature + docstring

            # For classes, extract method signatures
            elif component_type == "class" and in_component:
                if stripped.startswith(('def ', 'async def ')) and not stripped.startswith('    ') and brace_count == 0:
                    # This is a method definition
                    method_name = stripped.split('(')[0].replace('def ', '').replace('async def ', '')
                    context_parts.append(f"\nMethod: {method_name}")
                    # Extract method docstring
                    method_docstring = self._extract_docstring(lines, i)
                    if method_docstring:
                        context_parts.append(f"  Docstring: {method_docstring[:100]}...")

                # Track braces for nested structures
                brace_count += stripped.count('{') - stripped.count('}')
                if brace_count < 0:  # End of class
                    break

        # Limit total context length
        full_context = '\n'.join(context_parts)
        if len(full_context) > 1500:  # Reasonable limit
            full_context = full_context[:1500] + "\n\n[Context truncated for length]"

        return full_context

    def _extract_docstring(self, lines: List[str], start_idx: int) -> str:
        """Extract docstring starting from given line index"""
        if start_idx + 1 >= len(lines):
            return ""

        # Look for triple quotes
        line = lines[start_idx + 1].strip()
        if line.startswith('"""') or line.startswith("'''"):
            quote_type = '"""' if line.startswith('"""') else "'''"
            docstring_lines = []

            # First line
            first_line = line.replace(quote_type, '').strip()
            if first_line:
                docstring_lines.append(first_line)

            # Continue until closing quotes
            for i in range(start_idx + 2, len(lines)):
                line = lines[i]
                if quote_type in line:
                    # Last line
                    last_part = line.split(quote_type)[0].strip()
                    if last_part:
                        docstring_lines.append(last_part)
                    break
                else:
                    docstring_lines.append(line.strip())

            return '\n'.join(docstring_lines)
        return ""

    def _generate_frontend_docs(
        self, change: CodeChange
    ) -> Optional[DocumentationUpdate]:
        """Generate frontend documentation for components"""
        lines = change.content.split("\n")
        component_type = None
        component_name = None
        component_info = None

        for line in lines:
            if line.startswith("Component: "):
                component_type = "component"
                component_name = line.replace("Component: ", "")
            elif line.startswith("API call: "):
                component_type = "api_call"
                component_name = line.replace("API call: ", "")
            elif line.startswith("Info: ") or line.startswith("Context: "):
                component_info = line.replace("Info: ", "").replace("Context: ", "")

        if not component_type or not component_name:
            return None

        # Create frontend docs directory
        docs_path = self.docs_root / "technical" / "frontend" / "components.md"
        docs_path.parent.mkdir(parents=True, exist_ok=True)

        # Check if docs file exists
        if docs_path.exists():
            with open(docs_path, "r", encoding="utf-8") as f:
                current_content = f.read()

            # Check if component already documented
            if f"### {component_name}" in current_content:
                logger.info(f"Frontend component {component_name} already documented")
                return None

            change_type = "update"
        else:
            # Create new frontend file
            current_content = self._create_frontend_template()
            change_type = "create"

        # Generate component documentation
        component_docs = self._generate_frontend_component_docs(
            component_type, component_name, component_info, change.file_path
        )

        # Add to appropriate section
        section = (
            "React –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã" if component_type == "component" else "API –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"
        )
        if f"## {section}" in current_content:
            section_pattern = f"## {section}\n"
            insert_position = current_content.find(section_pattern) + len(
                section_pattern
            )
            updated_content = (
                current_content[:insert_position]
                + "\n"
                + component_docs
                + "\n"
                + current_content[insert_position:]
            )
        else:
            updated_content = current_content + f"\n## {section}\n\n{component_docs}\n"

        return DocumentationUpdate(
            file_path=str(docs_path), change_type=change_type, content=updated_content
        )

    def _create_frontend_template(self) -> str:
        """Create template for frontend documentation"""
        return """# Frontend –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

## –û–±–∑–æ—Ä

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ frontend —á–∞—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã ReAIboot.

## React –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

–ó–¥–µ—Å—å –æ–ø–∏—Å–∞–Ω—ã –æ—Å–Ω–æ–≤–Ω—ã–µ React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã.

## API –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

–ó–¥–µ—Å—å –æ–ø–∏—Å–∞–Ω—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å backend API –∏ –≤–Ω–µ—à–Ω–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏.

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Frontend

```
React Components <-> API Layer <-> Backend Services
```

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

- **React** - UI —Ñ—Ä–µ–π–º–≤–æ—Ä–∫
- **TypeScript** - —Ç–∏–ø–∏–∑–∞—Ü–∏—è
- **Next.js** - React —Ñ—Ä–µ–π–º–≤–æ—Ä–∫
- **Tailwind CSS** - —Å—Ç–∏–ª–∏–∑–∞—Ü–∏—è
"""

    def _generate_frontend_component_docs(
        self,
        component_type: str,
        component_name: str,
        component_info: str,
        file_path: str,
    ) -> str:
        """Generate documentation for frontend component"""

        if component_type == "component":
            return f"""### {component_name}

**–§–∞–π–ª:** `{file_path}`

**–û–ø–∏—Å–∞–Ω–∏–µ:** {component_info}

**–¢–∏–ø:** React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏–µ]

**Props:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑]

**–°–æ—Å—Ç–æ—è–Ω–∏–µ:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑]
"""

        elif component_type == "api_call":
            return f"""### API –≤—ã–∑–æ–≤: {component_name}

**–§–∞–π–ª:** `{file_path}`

**–ö–æ–Ω—Ç–µ–∫—Å—Ç:** {component_info}

**–¢–∏–ø –≤—ã–∑–æ–≤–∞:** [GET/POST/PUT/DELETE]

**–≠–Ω–¥–ø–æ–∏–Ω—Ç:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑]

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** [–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏–µ]
"""

        return f"### {component_name}\n\n–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"

    def apply_updates(self, updates: List[DocumentationUpdate]) -> None:
        """Apply documentation updates to files"""
        self.metrics["updates_applied"] = len(updates)

        for update in updates:
            docs_path = Path(update.file_path)

            # Create directory if it doesn't exist
            docs_path.parent.mkdir(parents=True, exist_ok=True)

            # Write content
            with open(docs_path, "w", encoding="utf-8") as f:
                f.write(update.content)

            logger.info(
                f"{'Created' if update.change_type == 'create' else 'Updated'} {update.file_path}"
            )

        # Generate metrics report
        self._generate_metrics_report()

        # Create documentation dashboard
        self._create_documentation_dashboard()

    def _generate_metrics_report(self) -> None:
        """Generate performance metrics report"""
        if not self.metrics["start_time"] or not self.metrics["end_time"]:
            return

        processing_time = self.metrics["end_time"] - self.metrics["start_time"]
        docs_path = self.docs_root / "metrics" / "performance.md"
        docs_path.parent.mkdir(parents=True, exist_ok=True)

        report = f"""# –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

## –û–±–∑–æ—Ä

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Ä–∞–±–æ—Ç–µ —Å–∏—Å—Ç–µ–º—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

- **–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:** {processing_time:.2f} —Å–µ–∫—É–Ω–¥
- **–§–∞–π–ª–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ:** {self.metrics["files_analyzed"]}
- **–ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ:** {self.metrics["changes_found"]}
- **–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–æ:** {self.metrics["updates_applied"]}
- **–û—à–∏–±–æ–∫:** {len(self.metrics["errors"])}

## –î–µ—Ç–∞–ª–∏ –∞–Ω–∞–ª–∏–∑–∞

### –ü–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤:
- **Python —Ñ–∞–π–ª—ã:** API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã, –∫–ª–∞—Å—Å—ã, —Ñ—É–Ω–∫—Ü–∏–∏, LLM –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
- **JavaScript/TypeScript:** React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, API –≤—ã–∑–æ–≤—ã
- **SQL —Ñ–∞–π–ª—ã:** –°—Ö–µ–º—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- **YAML —Ñ–∞–π–ª—ã:** –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

### –ü–æ —Ç–∏–ø–∞–º –∏–∑–º–µ–Ω–µ–Ω–∏–π:
- **API endpoints:** –ù–æ–≤—ã–µ –∏ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
- **Business logic:** –ö–ª–∞—Å—Å—ã, –º–µ—Ç–æ–¥—ã, LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
- **Frontend components:** React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏ API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
- **Configuration:** –ò–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫

## –û—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è

{chr(10).join(f"- {error}" for error in self.metrics["errors"]) if self.metrics["errors"] else "–û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"}

## –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:** {time.strftime('%Y-%m-%d %H:%M:%S')}
- **–í–µ—Ä—Å–∏—è Python:** {sys.version.split()[0]}
- **–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞:** {sys.platform}

---
*–≠—Ç–æ—Ç –æ—Ç—á–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –∫–∞–∂–¥–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.*
"""

        with open(docs_path, "w", encoding="utf-8") as f:
            f.write(report)

        logger.info(f"Performance metrics report generated: {docs_path}")

    def _create_documentation_dashboard(self) -> None:
        """Create a simple documentation dashboard"""
        dashboard_path = self.docs_root / "DASHBOARD.md"

        # Collect information about all documentation files
        docs_structure = self._analyze_docs_structure()

        dashboard = f"""# üìö Documentation Dashboard - ReAIboot

## –û–±–∑–æ—Ä —Å–∏—Å—Ç–µ–º—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π dashboard –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ ReAIboot!

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞

{self._get_project_metrics()}

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

### Business Documentation
{docs_structure.get('business', '–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ')}

### Technical Documentation
{docs_structure.get('technical', '–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ')}

### User Guides
{docs_structure.get('user_guides', '–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ')}

### Templates
{docs_structure.get('templates', '–í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ')}

## üîç –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫

### –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:
- [API Documentation](./technical/api/overview.md) - –í—Å–µ API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
- [Architecture](./technical/architecture/components.md) - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã
- [Frontend](./technical/frontend/components.md) - React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- [LLM Guide](./LLM_README.md) - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è –ò–ò

### –ü–æ —Ç–∏–ø–∞–º:
- üîß **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è** - API, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
- üíº **–ë–∏–∑–Ω–µ—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è** - —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –∞—É–¥–∏—Ç–æ—Ä–∏—è, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã
- üë• **–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –≥–∞–π–¥—ã** - –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- ü§ñ **LLM –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è** - —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è –ò–ò

## üöÄ –ë—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤:
1. **–û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é:** `python .cursorrules/update_docs.py --all`
2. **–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è:** `python .cursorrules/update_docs.py --dry-run --files src/`
3. **–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –º–µ—Ç—Ä–∏–∫–∏:** [Performance Metrics](./metrics/performance.md)

### –î–ª—è LLM:
1. **–ü—Ä–æ—á–∏—Ç–∞—Ç—å LLM_README.md** - –ø–æ–ª–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
2. **–ò–∑—É—á–∏—Ç—å API** - –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
3. **–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É** - –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è

## üìà –°—Ç–∞—Ç—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

### ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º—ã–µ —Ä–∞–∑–¥–µ–ª—ã:
- API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã (FastAPI)
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
- Frontend –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### üîÑ –¢—Ä–µ–±—É—é—â–∏–µ —Ä—É—á–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:
- –ë–∏–∑–Ω–µ—Å-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –≥–∞–π–¥—ã
- –î–∏–∑–∞–π–Ω-–¥–æ–∫—É–º–µ–Ω—Ç—ã

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [GitHub Repository](https://github.com/MrUversky/ReAIboot-Telegram-Analytics)
- [API Swagger](http://localhost:8000/api/docs) (–ø—Ä–∏ –∑–∞–ø—É—â–µ–Ω–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ)
- [Performance Metrics](./metrics/performance.md)

---

## üí° –°–æ–≤–µ—Ç—ã –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

### –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞:
1. –ù–∞—á–Ω–∏—Ç–µ —Å [LLM_README.md](./LLM_README.md) –µ—Å–ª–∏ –≤—ã –ò–ò
2. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ [Architecture Overview](./technical/architecture/components.md)
3. –û–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å [API Endpoints](./technical/api/overview.md)

### –î–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è:
1. –ò–∑—É—á–∏—Ç–µ [Business Documentation](./business/overview.md)
2. –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ [User Guides](./user-guides/getting-started.md)
3. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ [Performance Metrics](./metrics/performance.md)

---

*Dashboard –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏*
*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""

        with open(dashboard_path, "w", encoding="utf-8") as f:
            f.write(dashboard)

        logger.info(f"Documentation dashboard created: {dashboard_path}")

    def _analyze_docs_structure(self) -> Dict[str, str]:
        """Analyze the structure of documentation"""
        structure = {}

        # Business docs
        business_files = list((self.docs_root / "business").glob("*.md"))
        if business_files:
            structure["business"] = "\n".join(
                f"- [{f.stem.title()}](./business/{f.name})" for f in business_files
            )

        # Technical docs
        technical_dirs = ["api", "architecture", "database", "deployment", "frontend"]
        technical_content = []
        for dir_name in technical_dirs:
            dir_path = self.docs_root / "technical" / dir_name
            if dir_path.exists():
                files = list(dir_path.glob("*.md"))
                if files:
                    technical_content.append(f"**{dir_name.title()}:**")
                    technical_content.extend(
                        f"  - [{f.stem.replace('_', ' ').title()}](./technical/{dir_name}/{f.name})"
                        for f in files
                    )

        if technical_content:
            structure["technical"] = "\n".join(technical_content)

        # User guides
        user_guide_files = list((self.docs_root / "user-guides").glob("*.md"))
        if user_guide_files:
            structure["user_guides"] = "\n".join(
                f"- [{f.stem.replace('-', ' ').title()}](./user-guides/{f.name})"
                for f in user_guide_files
            )

        # Templates
        template_files = list((self.docs_root / "templates").glob("*.md"))
        if template_files:
            structure["templates"] = "\n".join(
                f"- [{f.stem.replace('-', ' ').title()}](./templates/{f.name})"
                for f in template_files
            )

        return structure

    def _get_project_metrics(self) -> str:
        """Get basic project metrics"""
        total_docs = len(list(self.docs_root.glob("**/*.md")))
        api_endpoints = len(
            list((self.docs_root / "technical" / "api" / "endpoints").glob("*.md"))
        )
        components = len(
            list((self.docs_root / "technical" / "architecture").glob("*.md"))
        )

        return f"""
- **–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {total_docs}
- **API —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤:** {api_endpoints}
- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:** {components}
- **–í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:** {time.strftime('%H:%M:%S')}
- **–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:** ‚úÖ –ê–∫—Ç–∏–≤–Ω–∞
"""


def main():
    parser = argparse.ArgumentParser(
        description="Auto-update documentation based on code changes"
    )
    parser.add_argument("--files", nargs="*", help="Files to analyze")
    parser.add_argument("--all", action="store_true", help="Update all documentation")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be updated without applying",
    )
    parser.add_argument(
        "--force-ai",
        action="store_true",
        help="Force AI regeneration for all components (expensive)",
    )

    args = parser.parse_args()

    # Determine project root
    script_dir = Path(__file__).parent.parent
    project_root = script_dir

    agent = DocumentationAgent(str(project_root), force_ai=args.force_ai)

    if args.all:
        # Analyze all Python files
        python_files = list(project_root.glob("src/**/*.py"))
        changed_files = [str(f.relative_to(project_root)) for f in python_files]
    elif args.files:
        changed_files = args.files
    else:
        # Try to get changed files from git
        import subprocess

        try:
            result = subprocess.run(
                ["git", "diff", "--name-only", "HEAD~1"],
                capture_output=True,
                text=True,
                cwd=project_root,
            )
            changed_files = (
                result.stdout.strip().split("\n") if result.stdout.strip() else []
            )
        except:
            logger.error("Could not get changed files from git")
            changed_files = []

    if not changed_files:
        logger.info("No files to analyze")
        return

    logger.info(f"Analyzing {len(changed_files)} files...")

    # Analyze changes
    changes = agent.analyze_changes(changed_files)
    logger.info(f"Found {len(changes)} relevant changes")

    # Generate updates
    updates = agent.generate_documentation_updates(changes)
    logger.info(f"Generated {len(updates)} documentation updates")

    if args.dry_run:
        for update in updates:
            print(f"Would {update.change_type}: {update.file_path}")
        return

    # Apply updates
    agent.apply_updates(updates)

    logger.info("Documentation update completed!")


if __name__ == "__main__":
    main()
